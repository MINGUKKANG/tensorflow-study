{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------- \n",
    "# the purpose of this code is to classify mnist data with convolutional neural network\n",
    "# when i write this code, i refered to https://github.com/Hvass-Labs/TensorFlow-Tutorials\n",
    "# I am not so good at English. So please be good to understand my awkward English. \n",
    "# ---------------------------------------------------------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import input_data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/',one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameta\n",
    "img_size = 28\n",
    "img_shape = (28,28)\n",
    "img_flat_length = 28*28*1\n",
    "num_channels = 1 # black and white\n",
    "filter_size1 = 5\n",
    "num_filters1 = 16\n",
    "filter_size2 = 5\n",
    "num_filters2 = 32\n",
    "fc_output1 = 128\n",
    "fc_output2 = 64 \n",
    "num_classes = 10\n",
    "training_epoch = 32\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels of True_test_Data\n",
    "data_test_cls = np.argmax(data.test.labels,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for plotting images\n",
    "def plot_img(images, data_true, data_pred = None):\n",
    "    # debugging code \n",
    "    assert len(images) == len(data_true) == 9\n",
    "    \n",
    "    # make Function used to plot 9 images in a 3*3 grid\n",
    "    fig,axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace = 0.3, wspace =0.3)\n",
    "    \n",
    "    for i,ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap = 'binary')\n",
    "        \n",
    "        if data_pred is None:\n",
    "            xlabel = \"True:{0}\".format(data_true[i])\n",
    "        else:\n",
    "            xlabel = \"True:{0}, Prediction:{1}\".format(data_true[i], data_pred[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        #Remove ticks from the plot\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function which makes convolutional network with relu and max_pooling layer.\n",
    "def conv_layer(input,filter_size, num_channels,num_filters, use_maxpooling = True):\n",
    "    shape = [filter_size,filter_size,num_channels,num_filters]\n",
    "    weight = tf.Variable(tf.random_normal(shape), name =\"weight\")\n",
    "    bias = tf.Variable(tf.random_normal([num_filters]), name = \"bias\")\n",
    "    layer = tf.nn.conv2d(input,weight,strides = [1,1,1,1],padding = \"SAME\")\n",
    "    layer += bias\n",
    "    \n",
    "    if use_maxpooling:\n",
    "        layer = tf.nn.max_pool(layer,ksize = [1,2,2,1], strides = [1,2,2,1], padding =\"SAME\")\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define flatting function for fully connected layer\n",
    "def flatting(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    length_layer = layer_shape[1:].num_elements()\n",
    "    layer_flated = tf.reshape(layer,[-1,length_layer])\n",
    "    \n",
    "    return length_layer,layer_flated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function for making fully connceted layer.\n",
    "def fully_connected(input, num_input,num_output,use_relu = True):\n",
    "    weight1 = tf.Variable(tf.random_normal([num_input,num_output]))\n",
    "    bias1 = tf.Variable(tf.random_normal([num_output]), name = \"bias_fully\")\n",
    "    logits = tf.matmul(input,weight1)+ bias1\n",
    "    \n",
    "    if use_relu:\n",
    "        logits = tf.nn.relu(logits)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder\n",
    "X = tf.placeholder(tf.float32, shape = [None,img_flat_length], name =\"INPUT\")\n",
    "Y = tf.placeholder(tf.float32, shape = [None,num_classes], name =\"Labels\")\n",
    "X_img = tf.reshape(X,[-1,img_size,img_size,num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first convolutional layer \n",
    "conv_layer1 = conv_layer(input = X_img,\n",
    "                         filter_size = filter_size1,\n",
    "                         num_channels = num_channels,\n",
    "                         num_filters = num_filters1,\n",
    "                         use_maxpooling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second convolutional layer\n",
    "conv_layer2 = conv_layer(input = conv_layer1,\n",
    "                         filter_size = filter_size2,\n",
    "                         num_channels = num_filters1,\n",
    "                         num_filters = num_filters2,\n",
    "                         use_maxpooling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten data for using fully_connected_layer\n",
    "length, flat_data = flatting(conv_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first fully connected layer\n",
    "layer_fc1 = fully_connected(input = flat_data,\n",
    "                            num_input = length,\n",
    "                            num_output = fc_output1,\n",
    "                            use_relu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second fully connected layer\n",
    "layer_fc2 = fully_connected(input = layer_fc1,\n",
    "                            num_input = fc_output1,\n",
    "                            num_output = fc_output2,\n",
    "                            use_relu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final fully connected layer\n",
    "layer_fc3 = fully_connected(input = layer_fc2,\n",
    "                            num_input = fc_output2,\n",
    "                            num_output = num_classes,\n",
    "                            use_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = tf.nn.softmax(layer_fc3)\n",
    "\n",
    "Y_pred_cls = tf.argmax(Y_pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cross_entropy\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = layer_fc3, labels = Y)\n",
    "# cost function\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "# we will use AdamOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 2e-3).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_correct = tf.equal(Y_pred_cls,tf.argmax(Y,1))\n",
    "\n",
    "Accuracy = tf.reduce_mean(tf.cast(is_correct, dtype = tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# create Session and initialize all variables\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Cost_val:2742.7966803533354\n",
      "Epoch:1 Cost_val:364.68330546985965\n",
      "Epoch:2 Cost_val:189.15237722917024\n",
      "Epoch:3 Cost_val:111.05169261932373\n",
      "Epoch:4 Cost_val:69.2578331617875\n",
      "Epoch:5 Cost_val:47.287187738418524\n",
      "Epoch:6 Cost_val:28.870992461551317\n",
      "Epoch:7 Cost_val:19.51496156036691\n",
      "Epoch:8 Cost_val:13.126241816431266\n",
      "Epoch:9 Cost_val:12.245110109502606\n",
      "Epoch:10 Cost_val:6.979998445951749\n",
      "Epoch:11 Cost_val:6.7967699582095795\n",
      "Epoch:12 Cost_val:5.131809255312171\n",
      "Epoch:13 Cost_val:5.627765310296407\n",
      "Epoch:14 Cost_val:3.289086319178305\n",
      "Epoch:15 Cost_val:4.648551783607065\n",
      "Epoch:16 Cost_val:4.580509715230561\n",
      "Epoch:17 Cost_val:4.215251001884843\n",
      "Epoch:18 Cost_val:3.1305839595717586\n",
      "Epoch:19 Cost_val:2.8418059651725525\n",
      "Epoch:20 Cost_val:2.52280446770824\n",
      "Epoch:21 Cost_val:2.8491290623466727\n",
      "Epoch:22 Cost_val:2.07450914410348\n",
      "Epoch:23 Cost_val:2.096608684135064\n",
      "Epoch:24 Cost_val:2.737486887677177\n",
      "Epoch:25 Cost_val:2.01425163098129\n",
      "Epoch:26 Cost_val:1.806057085003832\n",
      "Epoch:27 Cost_val:1.8496469568124878\n",
      "Epoch:28 Cost_val:1.1033052234096172\n",
      "Epoch:29 Cost_val:1.902319527489525\n",
      "Epoch:30 Cost_val:1.8783022381292327\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(training_epoch):\n",
    "    cost_val = 0\n",
    "    total_batch = int(data.train.num_examples/batch_size)\n",
    "    for k in range(total_batch):\n",
    "        batch_xs, batch_ys = data.train.next_batch(total_batch)\n",
    "        c,_ = sess.run([cost,optimizer], feed_dict = {X:batch_xs, Y:batch_ys})\n",
    "        cost_val += c/total_batch\n",
    "    print(\"Epoch:{0}\".format(epoch), \"Cost_val:{0}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate Accuracy\n",
    "Accuracy_val,Y_pred_val,correct = sess.run([Accuracy,Y_pred_cls,is_correct], feed_dict = {X:data.test.images, Y:data.test.labels})\n",
    "print(\"Accuracy is {0}\".format(Accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot examples of error\n",
    "def plot_examples_error():\n",
    "    \n",
    "#--------search error location -----------------------    \n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    q = data.test.images[incorrect]\n",
    "    w = data_test_cls[incorrect]\n",
    "    e = Y_pred_val[incorrect]\n",
    "    \n",
    "    q = q[0:9]\n",
    "    w = w[0:9]\n",
    "    e = e[0:9]\n",
    "#--------------- end ---------------------------------\n",
    "    # plotting images which have errors.\n",
    "    plot_img(images = q, data_true=w, data_pred = e)\n",
    "\n",
    "plot_examples_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "def plot_confusion_matrix():\n",
    "    data_true1 = data_test_cls\n",
    "    data_pred1 = Y_pred_val\n",
    "    \n",
    "    cm = confusion_matrix(data_true1,data_pred1)\n",
    "    \n",
    "    print(cm)\n",
    "    plt.matshow(cm)\n",
    "    \n",
    "    \n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
